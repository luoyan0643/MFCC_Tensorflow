{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wave' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e1154d6f3037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cough1.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wave' is not defined"
     ]
    }
   ],
   "source": [
    "wave.open('cough1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "file does not start with RIFF id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e1154d6f3037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cough1.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/wave.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/wave.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# else, assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitfp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/wave.py\u001b[0m in \u001b[0;36minitfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigendian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'RIFF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file does not start with RIFF id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'WAVE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not a WAVE file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: file does not start with RIFF id"
     ]
    }
   ],
   "source": [
    "wave.open('cough1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "file does not start with RIFF id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ecac7da1921b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cough1.wav'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/wave.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/wave.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# else, assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitfp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/wave.py\u001b[0m in \u001b[0;36minitfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigendian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'RIFF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file does not start with RIFF id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'WAVE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not a WAVE file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: file does not start with RIFF id"
     ]
    }
   ],
   "source": [
    "wave.open('cough1.wav','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c789ed94da0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwav_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cough1.m4a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"m4a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "wav_audio = AudioSegment.from_file(\"cough.m4a\", format=\"m4a\")\n",
    "\n",
    "\n",
    "wav_audio.export(\"audio.wav\", format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install pydub\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more informations on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-fee46b6fe551>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-fee46b6fe551>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    conda install pydub\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conda install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-fee46b6fe551>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-fee46b6fe551>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    conda install pydub\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conda install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='audio.wav'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "wav_audio = AudioSegment.from_file(\"cough.m4a\", format=\"m4a\")\n",
    "\n",
    "\n",
    "wav_audio.export(\"audio.wav\", format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.8294784580499\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import contextlib\n",
    "fname = 'audio.wav'\n",
    "with contextlib.closing(wave.open(fname,'r')) as f:\n",
    "    frames = f.getnframes()\n",
    "    rate = f.getframerate()\n",
    "    duration = frames / float(rate)\n",
    "    print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "for i in range(0,int(duration)):\n",
    "    t1 = i * 1000 #Works in milliseconds\n",
    "    t2 = t1+1000\n",
    "    newAudio = AudioSegment.from_wav(\"audio.wav\")\n",
    "    newAudio = newAudio[t1:t2]\n",
    "    newAudio.export('newSong'+str(i)+'.wav', format=\"wav\") #Exports to a wav file in the current path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "y, sr = librosa.load('newSong5.wav',sr=44100,duration=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=y, sr=44100, n_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCDAAUAYBBgDKIMAAQBn/A0b75E9Qdi3PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c244dfc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4, 4))\n",
    "librosa.display.specshow(mfccs, x_axis='time')\n",
    "frame1 = plt.gca()\n",
    "frame1.axes.get_xaxis().set_ticks([])\n",
    "frame1.axes.get_yaxis().set_ticks([])\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig('newSong.png', bbox_inches='tight',pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "for i in range(0,int(duration)):\n",
    "    t1 = i * 1000 #Works in milliseconds\n",
    "    t2 = t1+1000\n",
    "    newAudio = AudioSegment.from_wav(\"audio.wav\")\n",
    "    newAudio = newAudio[t1:t2]\n",
    "    newAudio.export('test.wav', format=\"wav\")\n",
    "    y, sr = librosa.load('test.wav',sr=44100,duration=1)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=44100, n_mfcc=40)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time')\n",
    "    frame1 = plt.gca()\n",
    "    frame1.axes.get_xaxis().set_ticks([])\n",
    "    frame1.axes.get_yaxis().set_ticks([])\n",
    "    plt.xlabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('audio'+str(i)+'.png', bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "def read_images_from(path):\n",
    "  images = []\n",
    "  png_files_path = glob.glob(os.path.join(path, '*.[pP][nN][gG]'))\n",
    "  for filename in png_files_path:\n",
    "    im = Image.open(filename)  # .convert(\"L\")  # Convert to greyscale\n",
    "    im=im.resize([56,56])\n",
    "    im = im.convert('LA')\n",
    "    im = np.asarray(im, np.uint8)\n",
    "    # print(type(im))\n",
    "    # get only images name, not path\n",
    "    image_name = filename.split('.')[0].split('o')[-1]\n",
    "    images.append([int(image_name), im])\n",
    "\n",
    "  images = sorted(images, key=lambda image: image[0])\n",
    "\n",
    "  images_only = [np.asarray(image[1], np.uint8) for image in images]  # Use unint8 or you will be !!!\n",
    "  images_only = np.array(images_only)\n",
    "\n",
    "  print(images_only.shape)\n",
    "  return images_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 56, 56, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180, 56, 56, 1)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=read_images_from('')\n",
    "images=images[:,:,:,0]\n",
    "y = np.expand_dims(images, axis=3)\n",
    "y.shape\n",
    "images=y\n",
    "images=images[:180,:,:,:]\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels=np.array(np.zeros(180))\n",
    "print(labels.shape[0])\n",
    "cough=np.array([13,14,23,35,53,54,36,73,102,127,168])\n",
    "labels[cough]=0.99\n",
    "labels=labels.astype(int)\n",
    "#for i in range(199):\n",
    "#    if i in cough:\n",
    "#        labels[i][1]=1\n",
    "#        labels[i][0]=0\n",
    "#    else:\n",
    "#        labels[i][1]=0\n",
    "#        labels[i][0]=1\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import LeNet5_infernece\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 60\n",
    "LEARNING_RATE_BASE = 0.01\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 6000\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "\n",
    "def  train(images,labels):\n",
    "         # 定义输出为4维矩阵的placeholder# 定义输出为 \n",
    "    x = tf.placeholder(tf.float32, [\n",
    "            BATCH_SIZE,\n",
    "            LeNet5_infernece.IMAGE_SIZE,\n",
    "            LeNet5_infernece.IMAGE_SIZE,\n",
    "            LeNet5_infernece.NUM_CHANNELS],\n",
    "        name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None], name='y-input')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=50)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    y = LeNet5_infernece.inference(x,False,regularizer)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # 定义损失函数、学习率、滑动平均操作以及训练过程。\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    y_=tf.cast(y_, tf.int32)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=y_)\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses'))\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        labels.shape[0] / BATCH_SIZE, LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "        # 初始化TensorFlow持久化类。\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        next_element = iterator.get_next()\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            xs, ys = next_element\n",
    "            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs.eval(), y_: ys.eval()})\n",
    "            print(\"After %d training step(s), loss on training batch is %g.\" % (step, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 training step(s), loss on training batch is 8.73423.\n",
      "After 2 training step(s), loss on training batch is 8.73422.\n",
      "After 3 training step(s), loss on training batch is 8.7342.\n",
      "After 4 training step(s), loss on training batch is 8.73418.\n",
      "After 5 training step(s), loss on training batch is 8.73417.\n",
      "After 6 training step(s), loss on training batch is 8.73415.\n",
      "After 7 training step(s), loss on training batch is 8.73413.\n",
      "After 8 training step(s), loss on training batch is 8.73411.\n",
      "After 9 training step(s), loss on training batch is 8.7341.\n",
      "After 10 training step(s), loss on training batch is 8.73408.\n",
      "After 11 training step(s), loss on training batch is 8.73406.\n",
      "After 12 training step(s), loss on training batch is 8.73405.\n",
      "After 13 training step(s), loss on training batch is 8.73403.\n",
      "After 14 training step(s), loss on training batch is 8.73401.\n",
      "After 15 training step(s), loss on training batch is 8.734.\n",
      "After 16 training step(s), loss on training batch is 8.73398.\n",
      "After 17 training step(s), loss on training batch is 8.73396.\n",
      "After 18 training step(s), loss on training batch is 8.73395.\n",
      "After 19 training step(s), loss on training batch is 8.73393.\n",
      "After 20 training step(s), loss on training batch is 8.73391.\n",
      "After 21 training step(s), loss on training batch is 8.7339.\n",
      "After 22 training step(s), loss on training batch is 8.73388.\n",
      "After 23 training step(s), loss on training batch is 8.73387.\n",
      "After 24 training step(s), loss on training batch is 8.73385.\n",
      "After 25 training step(s), loss on training batch is 8.73383.\n",
      "After 26 training step(s), loss on training batch is 8.73382.\n",
      "After 27 training step(s), loss on training batch is 8.7338.\n",
      "After 28 training step(s), loss on training batch is 8.73379.\n",
      "After 29 training step(s), loss on training batch is 8.73377.\n",
      "After 30 training step(s), loss on training batch is 8.73375.\n",
      "After 31 training step(s), loss on training batch is 8.73374.\n",
      "After 32 training step(s), loss on training batch is 8.73372.\n",
      "After 33 training step(s), loss on training batch is 8.73371.\n",
      "After 34 training step(s), loss on training batch is 8.73369.\n",
      "After 35 training step(s), loss on training batch is 8.73368.\n",
      "After 36 training step(s), loss on training batch is 8.73366.\n",
      "After 37 training step(s), loss on training batch is 8.73364.\n",
      "After 38 training step(s), loss on training batch is 8.73363.\n",
      "After 39 training step(s), loss on training batch is 8.73361.\n",
      "After 40 training step(s), loss on training batch is 8.7336.\n",
      "After 41 training step(s), loss on training batch is 8.73358.\n",
      "After 42 training step(s), loss on training batch is 8.73357.\n",
      "After 43 training step(s), loss on training batch is 8.73355.\n",
      "After 44 training step(s), loss on training batch is 8.73354.\n",
      "After 45 training step(s), loss on training batch is 8.73352.\n",
      "After 46 training step(s), loss on training batch is 8.73351.\n",
      "After 47 training step(s), loss on training batch is 8.73349.\n",
      "After 48 training step(s), loss on training batch is 8.73348.\n",
      "After 49 training step(s), loss on training batch is 8.73346.\n",
      "After 50 training step(s), loss on training batch is 8.73345.\n",
      "After 51 training step(s), loss on training batch is 8.73343.\n",
      "After 52 training step(s), loss on training batch is 8.73342.\n",
      "After 53 training step(s), loss on training batch is 8.73341.\n",
      "After 54 training step(s), loss on training batch is 8.73339.\n",
      "After 55 training step(s), loss on training batch is 8.73338.\n",
      "After 56 training step(s), loss on training batch is 8.73336.\n",
      "After 57 training step(s), loss on training batch is 8.73335.\n",
      "After 58 training step(s), loss on training batch is 8.73333.\n",
      "After 59 training step(s), loss on training batch is 8.73332.\n",
      "After 60 training step(s), loss on training batch is 8.7333.\n",
      "After 61 training step(s), loss on training batch is 8.73329.\n",
      "After 62 training step(s), loss on training batch is 8.73327.\n",
      "After 63 training step(s), loss on training batch is 8.73326.\n",
      "After 64 training step(s), loss on training batch is 8.73324.\n",
      "After 65 training step(s), loss on training batch is 8.73323.\n",
      "After 66 training step(s), loss on training batch is 8.73322.\n",
      "After 67 training step(s), loss on training batch is 8.7332.\n",
      "After 68 training step(s), loss on training batch is 8.73319.\n",
      "After 69 training step(s), loss on training batch is 8.73317.\n",
      "After 70 training step(s), loss on training batch is 8.73316.\n",
      "After 71 training step(s), loss on training batch is 8.73315.\n",
      "After 72 training step(s), loss on training batch is 8.73313.\n",
      "After 73 training step(s), loss on training batch is 8.73312.\n",
      "After 74 training step(s), loss on training batch is 8.73311.\n",
      "After 75 training step(s), loss on training batch is 8.73309.\n",
      "After 76 training step(s), loss on training batch is 8.73308.\n",
      "After 77 training step(s), loss on training batch is 8.73306.\n",
      "After 78 training step(s), loss on training batch is 8.73305.\n",
      "After 79 training step(s), loss on training batch is 8.73304.\n",
      "After 80 training step(s), loss on training batch is 8.73302.\n",
      "After 81 training step(s), loss on training batch is 8.73301.\n",
      "After 82 training step(s), loss on training batch is 8.733.\n",
      "After 83 training step(s), loss on training batch is 8.73298.\n",
      "After 84 training step(s), loss on training batch is 8.73297.\n",
      "After 85 training step(s), loss on training batch is 8.73296.\n",
      "After 86 training step(s), loss on training batch is 8.73294.\n",
      "After 87 training step(s), loss on training batch is 8.73293.\n",
      "After 88 training step(s), loss on training batch is 8.73292.\n",
      "After 89 training step(s), loss on training batch is 8.73291.\n",
      "After 90 training step(s), loss on training batch is 8.73289.\n",
      "After 91 training step(s), loss on training batch is 8.73288.\n",
      "After 92 training step(s), loss on training batch is 8.73287.\n",
      "After 93 training step(s), loss on training batch is 8.73285.\n",
      "After 94 training step(s), loss on training batch is 8.73284.\n",
      "After 95 training step(s), loss on training batch is 8.73283.\n",
      "After 96 training step(s), loss on training batch is 8.73281.\n",
      "After 97 training step(s), loss on training batch is 8.7328.\n",
      "After 98 training step(s), loss on training batch is 8.73279.\n",
      "After 99 training step(s), loss on training batch is 8.73278.\n",
      "After 100 training step(s), loss on training batch is 8.73276.\n",
      "After 101 training step(s), loss on training batch is 8.73275.\n",
      "After 102 training step(s), loss on training batch is 8.73274.\n",
      "After 103 training step(s), loss on training batch is 8.73273.\n",
      "After 104 training step(s), loss on training batch is 8.73272.\n",
      "After 105 training step(s), loss on training batch is 8.7327.\n",
      "After 106 training step(s), loss on training batch is 8.73269.\n",
      "After 107 training step(s), loss on training batch is 8.73268.\n",
      "After 108 training step(s), loss on training batch is 8.73267.\n",
      "After 109 training step(s), loss on training batch is 8.73265.\n",
      "After 110 training step(s), loss on training batch is 8.73264.\n",
      "After 111 training step(s), loss on training batch is 8.73263.\n",
      "After 112 training step(s), loss on training batch is 8.73262.\n",
      "After 113 training step(s), loss on training batch is 8.73261.\n",
      "After 114 training step(s), loss on training batch is 8.73259.\n",
      "After 115 training step(s), loss on training batch is 8.73258.\n",
      "After 116 training step(s), loss on training batch is 8.73257.\n",
      "After 117 training step(s), loss on training batch is 8.73256.\n",
      "After 118 training step(s), loss on training batch is 8.73255.\n",
      "After 119 training step(s), loss on training batch is 8.73253.\n",
      "After 120 training step(s), loss on training batch is 8.73252.\n",
      "After 121 training step(s), loss on training batch is 8.73251.\n",
      "After 122 training step(s), loss on training batch is 8.7325.\n",
      "After 123 training step(s), loss on training batch is 8.73249.\n",
      "After 124 training step(s), loss on training batch is 8.73247.\n",
      "After 125 training step(s), loss on training batch is 8.73246.\n",
      "After 126 training step(s), loss on training batch is 8.73245.\n",
      "After 127 training step(s), loss on training batch is 8.73244.\n",
      "After 128 training step(s), loss on training batch is 8.73243.\n",
      "After 129 training step(s), loss on training batch is 8.73242.\n",
      "After 130 training step(s), loss on training batch is 8.73241.\n",
      "After 131 training step(s), loss on training batch is 8.7324.\n",
      "After 132 training step(s), loss on training batch is 8.73238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 133 training step(s), loss on training batch is 8.73237.\n",
      "After 134 training step(s), loss on training batch is 8.73236.\n",
      "After 135 training step(s), loss on training batch is 8.73235.\n",
      "After 136 training step(s), loss on training batch is 8.73234.\n",
      "After 137 training step(s), loss on training batch is 8.73233.\n",
      "After 138 training step(s), loss on training batch is 8.73232.\n",
      "After 139 training step(s), loss on training batch is 8.73231.\n",
      "After 140 training step(s), loss on training batch is 8.7323.\n",
      "After 141 training step(s), loss on training batch is 8.73228.\n",
      "After 142 training step(s), loss on training batch is 8.73227.\n",
      "After 143 training step(s), loss on training batch is 8.73226.\n",
      "After 144 training step(s), loss on training batch is 8.73225.\n",
      "After 145 training step(s), loss on training batch is 8.73224.\n",
      "After 146 training step(s), loss on training batch is 8.73223.\n",
      "After 147 training step(s), loss on training batch is 8.73222.\n",
      "After 148 training step(s), loss on training batch is 8.73221.\n",
      "After 149 training step(s), loss on training batch is 8.7322.\n",
      "After 150 training step(s), loss on training batch is 8.73219.\n",
      "After 151 training step(s), loss on training batch is 8.73218.\n",
      "After 152 training step(s), loss on training batch is 8.73217.\n",
      "After 153 training step(s), loss on training batch is 8.73216.\n",
      "After 154 training step(s), loss on training batch is 8.73214.\n",
      "After 155 training step(s), loss on training batch is 8.73213.\n",
      "After 156 training step(s), loss on training batch is 8.73212.\n",
      "After 157 training step(s), loss on training batch is 8.73211.\n",
      "After 158 training step(s), loss on training batch is 8.7321.\n",
      "After 159 training step(s), loss on training batch is 8.73209.\n",
      "After 160 training step(s), loss on training batch is 8.73208.\n",
      "After 161 training step(s), loss on training batch is 8.73207.\n",
      "After 162 training step(s), loss on training batch is 8.73206.\n",
      "After 163 training step(s), loss on training batch is 8.73205.\n",
      "After 164 training step(s), loss on training batch is 8.73204.\n",
      "After 165 training step(s), loss on training batch is 8.73203.\n",
      "After 166 training step(s), loss on training batch is 8.73202.\n",
      "After 167 training step(s), loss on training batch is 8.73201.\n",
      "After 168 training step(s), loss on training batch is 8.732.\n",
      "After 169 training step(s), loss on training batch is 8.73199.\n",
      "After 170 training step(s), loss on training batch is 8.73198.\n",
      "After 171 training step(s), loss on training batch is 8.73197.\n",
      "After 172 training step(s), loss on training batch is 8.73196.\n",
      "After 173 training step(s), loss on training batch is 8.73195.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-d296bd7183f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-214-d296bd7183f4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-213-b6861ae68e45>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After %d training step(s), loss on training batch is %g.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    tf.reset_default_graph()\n",
    "    train(images,labels)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "xtest, ytest = iterator.get_next()\n",
    "with tf.Session().as_default():\n",
    "    print(ytest.eval().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
